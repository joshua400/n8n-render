{"version":3,"file":"chat_models.cjs","names":["AbstractGoogleLLMConnection","fields: GoogleAIBaseLLMInput<AuthOptions> | undefined","caller: AsyncCaller","client: GoogleAbstractedClient","streaming: boolean","apiConfig: GeminiAPIConfig","geminiConfig: GeminiAPIConfig","getGeminiAPI","BaseChatModel","fields?: ChatGoogleBaseInput<AuthOptions>","ensureParams","copyAndValidateModelParamsInto","DefaultGeminiSafetyHandler","options: this[\"ParsedCallOptions\"]","apiKey: string","ApiKeyGoogleAuth","fields?: GoogleAIBaseLLMInput<AuthOptions>","fields: GoogleBaseLLMInput<AuthOptions>","tools: GoogleAIToolType[]","kwargs?: Partial<GoogleAIBaseLanguageModelCallOptions>","convertToGeminiTools","options?: this[\"ParsedCallOptions\"]","copyAIModelParams","messages: BaseMessage[]","runManager: CallbackManagerForLLMRun | undefined","finalChunk: ChatGenerationChunk | null","chunk","_messages: BaseMessage[]","runManager?: CallbackManagerForLLMRun","usageMetadata: UsageMetadata | undefined","ChatGenerationChunk","AIMessageChunk","PROFILES","outputSchema:\n      | InteropZodType<RunOutput>\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      | Record<string, any>","config?: StructuredOutputMethodOptions<boolean>","schema: InteropZodType<RunOutput> | Record<string, any>","outputParser: BaseLLMOutputParser<RunOutput>","tools: GeminiTool[]","schemaToGeminiParameters","JsonOutputKeyToolsParser","geminiFunctionDefinition: GeminiFunctionDeclaration","parameters: GeminiJsonSchema","removeAdditionalProperties","RunnablePassthrough","input: any","config","RunnableSequence"],"sources":["../src/chat_models.ts"],"sourcesContent":["import { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { UsageMetadata, type BaseMessage } from \"@langchain/core/messages\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\n\nimport {\n  BaseChatModel,\n  LangSmithParams,\n  type BaseChatModelParams,\n} from \"@langchain/core/language_models/chat_models\";\nimport { ChatGenerationChunk, ChatResult } from \"@langchain/core/outputs\";\nimport { AIMessageChunk } from \"@langchain/core/messages\";\nimport {\n  BaseLanguageModelInput,\n  StructuredOutputMethodOptions,\n} from \"@langchain/core/language_models/base\";\nimport { type ModelProfile } from \"@langchain/core/language_models/profile\";\nimport {\n  Runnable,\n  RunnablePassthrough,\n  RunnableSequence,\n} from \"@langchain/core/runnables\";\nimport { JsonOutputKeyToolsParser } from \"@langchain/core/output_parsers/openai_tools\";\nimport { BaseLLMOutputParser } from \"@langchain/core/output_parsers\";\nimport { AsyncCaller } from \"@langchain/core/utils/async_caller\";\nimport { concat } from \"@langchain/core/utils/stream\";\nimport {\n  InteropZodType,\n  isInteropZodSchema,\n} from \"@langchain/core/utils/types\";\nimport {\n  GoogleAIBaseLLMInput,\n  GoogleAIModelParams,\n  GoogleAISafetySetting,\n  GoogleConnectionParams,\n  GooglePlatformType,\n  GeminiTool,\n  GoogleAIBaseLanguageModelCallOptions,\n  GoogleAIAPI,\n  GoogleAIAPIParams,\n  GoogleSearchToolSetting,\n  GoogleSpeechConfig,\n  GeminiJsonSchema,\n} from \"./types.js\";\nimport {\n  convertToGeminiTools,\n  copyAIModelParams,\n  copyAndValidateModelParamsInto,\n} from \"./utils/common.js\";\nimport { AbstractGoogleLLMConnection } from \"./connection.js\";\nimport { DefaultGeminiSafetyHandler, getGeminiAPI } from \"./utils/gemini.js\";\nimport { ApiKeyGoogleAuth, GoogleAbstractedClient } from \"./auth.js\";\nimport { JsonStream } from \"./utils/stream.js\";\nimport { ensureParams } from \"./utils/failed_handler.js\";\nimport type {\n  GoogleBaseLLMInput,\n  GoogleAISafetyHandler,\n  GoogleAISafetyParams,\n  GeminiFunctionDeclaration,\n  GeminiFunctionSchema,\n  GoogleAIToolType,\n  GeminiAPIConfig,\n  GoogleAIModelModality,\n} from \"./types.js\";\nimport {\n  removeAdditionalProperties,\n  schemaToGeminiParameters,\n} from \"./utils/zod_to_gemini_parameters.js\";\nimport PROFILES from \"./profiles.js\";\n\nexport class ChatConnection<AuthOptions> extends AbstractGoogleLLMConnection<\n  BaseMessage[],\n  AuthOptions\n> {\n  convertSystemMessageToHumanContent: boolean | undefined;\n\n  constructor(\n    fields: GoogleAIBaseLLMInput<AuthOptions> | undefined,\n    caller: AsyncCaller,\n    client: GoogleAbstractedClient,\n    streaming: boolean\n  ) {\n    super(fields, caller, client, streaming);\n    this.convertSystemMessageToHumanContent =\n      fields?.convertSystemMessageToHumanContent;\n  }\n\n  get useSystemInstruction(): boolean {\n    return typeof this.convertSystemMessageToHumanContent === \"boolean\"\n      ? !this.convertSystemMessageToHumanContent\n      : this.computeUseSystemInstruction;\n  }\n\n  get computeUseSystemInstruction(): boolean {\n    // This works on models from April 2024 and later\n    //   Vertex AI: gemini-1.5-pro and gemini-1.0-002 and later\n    //   AI Studio: gemini-1.5-pro-latest\n    if (this.modelFamily === \"palm\") {\n      return false;\n    } else if (this.modelName === \"gemini-1.0-pro-001\") {\n      return false;\n    } else if (this.modelName.startsWith(\"gemini-pro-vision\")) {\n      return false;\n    } else if (this.modelName.startsWith(\"gemini-1.0-pro-vision\")) {\n      return false;\n    } else if (this.modelName === \"gemini-pro\" && this.platform === \"gai\") {\n      // on AI Studio gemini-pro is still pointing at gemini-1.0-pro-001\n      return false;\n    } else if (this.modelFamily === \"gemma\") {\n      // At least as of 12 Mar 2025 gemma 3 on AIS, trying to use system instructions yields an error:\n      // \"Developer instruction is not enabled for models/gemma-3-27b-it\"\n      return false;\n    }\n    return true;\n  }\n\n  computeGoogleSearchToolAdjustmentFromModel(): Exclude<\n    GoogleSearchToolSetting,\n    boolean\n  > {\n    if (this.modelName.startsWith(\"gemini-1.0\")) {\n      return \"googleSearchRetrieval\";\n    } else if (this.modelName.startsWith(\"gemini-1.5\")) {\n      return \"googleSearchRetrieval\";\n    } else {\n      return \"googleSearch\";\n    }\n  }\n\n  computeGoogleSearchToolAdjustment(\n    apiConfig: GeminiAPIConfig\n  ): Exclude<GoogleSearchToolSetting, true> {\n    const adj = apiConfig.googleSearchToolAdjustment;\n    if (adj === undefined || adj === true) {\n      return this.computeGoogleSearchToolAdjustmentFromModel();\n    } else {\n      return adj;\n    }\n  }\n\n  buildGeminiAPI(): GoogleAIAPI {\n    const apiConfig: GeminiAPIConfig =\n      (this.apiConfig as GeminiAPIConfig) ?? {};\n    const googleSearchToolAdjustment =\n      this.computeGoogleSearchToolAdjustment(apiConfig);\n    const geminiConfig: GeminiAPIConfig = {\n      useSystemInstruction: this.useSystemInstruction,\n      googleSearchToolAdjustment,\n      ...apiConfig,\n    };\n    return getGeminiAPI(geminiConfig);\n  }\n\n  get api(): GoogleAIAPI {\n    switch (this.apiName) {\n      case \"google\":\n        return this.buildGeminiAPI();\n      default:\n        return super.api;\n    }\n  }\n}\n\n/**\n * Input to chat model class.\n */\nexport interface ChatGoogleBaseInput<AuthOptions>\n  extends BaseChatModelParams,\n    GoogleConnectionParams<AuthOptions>,\n    GoogleAIModelParams,\n    GoogleAISafetyParams,\n    GoogleAIAPIParams,\n    Pick<GoogleAIBaseLanguageModelCallOptions, \"streamUsage\"> {}\n\n/**\n * Integration with a Google chat model.\n */\nexport abstract class ChatGoogleBase<AuthOptions>\n  extends BaseChatModel<GoogleAIBaseLanguageModelCallOptions, AIMessageChunk>\n  implements ChatGoogleBaseInput<AuthOptions>\n{\n  // Used for tracing, replace with the same name as your class\n  static lc_name() {\n    return \"ChatGoogle\";\n  }\n\n  get lc_secrets(): { [key: string]: string } | undefined {\n    return {\n      authOptions: \"GOOGLE_AUTH_OPTIONS\",\n    };\n  }\n\n  lc_serializable = true;\n\n  // Set based on modelName\n  model: string;\n\n  modelName = \"gemini-pro\";\n\n  temperature: number;\n\n  maxOutputTokens: number;\n\n  maxReasoningTokens: number;\n\n  topP: number;\n\n  topK: number;\n\n  seed: number;\n\n  presencePenalty: number;\n\n  frequencyPenalty: number;\n\n  stopSequences: string[] = [];\n\n  logprobs: boolean;\n\n  topLogprobs: number = 0;\n\n  safetySettings: GoogleAISafetySetting[] = [];\n\n  responseModalities?: GoogleAIModelModality[];\n\n  // May intentionally be undefined, meaning to compute this.\n  convertSystemMessageToHumanContent: boolean | undefined;\n\n  safetyHandler: GoogleAISafetyHandler;\n\n  speechConfig: GoogleSpeechConfig;\n\n  streamUsage = true;\n\n  streaming = false;\n\n  labels?: Record<string, string>;\n\n  protected connection: ChatConnection<AuthOptions>;\n\n  protected streamedConnection: ChatConnection<AuthOptions>;\n\n  constructor(fields?: ChatGoogleBaseInput<AuthOptions>) {\n    super(ensureParams(fields));\n\n    copyAndValidateModelParamsInto(fields, this);\n    this.safetyHandler =\n      fields?.safetyHandler ?? new DefaultGeminiSafetyHandler();\n    this.streamUsage = fields?.streamUsage ?? this.streamUsage;\n    const client = this.buildClient(fields);\n    this.buildConnection(fields ?? {}, client);\n  }\n\n  getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {\n    const params = this.invocationParams(options);\n    return {\n      ls_provider: \"google_vertexai\",\n      ls_model_name: this.model,\n      ls_model_type: \"chat\",\n      ls_temperature: params.temperature ?? undefined,\n      ls_max_tokens: params.maxOutputTokens ?? undefined,\n      ls_stop: options.stop,\n    };\n  }\n\n  abstract buildAbstractedClient(\n    fields?: GoogleAIBaseLLMInput<AuthOptions>\n  ): GoogleAbstractedClient;\n\n  buildApiKeyClient(apiKey: string): GoogleAbstractedClient {\n    return new ApiKeyGoogleAuth(apiKey);\n  }\n\n  buildApiKey(fields?: GoogleAIBaseLLMInput<AuthOptions>): string | undefined {\n    return fields?.apiKey ?? getEnvironmentVariable(\"GOOGLE_API_KEY\");\n  }\n\n  buildClient(\n    fields?: GoogleAIBaseLLMInput<AuthOptions>\n  ): GoogleAbstractedClient {\n    const apiKey = this.buildApiKey(fields);\n    if (apiKey) {\n      return this.buildApiKeyClient(apiKey);\n    } else {\n      return this.buildAbstractedClient(fields);\n    }\n  }\n\n  buildConnection(\n    fields: GoogleBaseLLMInput<AuthOptions>,\n    client: GoogleAbstractedClient\n  ) {\n    this.connection = new ChatConnection(\n      { ...fields, ...this },\n      this.caller,\n      client,\n      false\n    );\n\n    this.streamedConnection = new ChatConnection(\n      { ...fields, ...this },\n      this.caller,\n      client,\n      true\n    );\n  }\n\n  get platform(): GooglePlatformType {\n    return this.connection.platform;\n  }\n\n  override bindTools(\n    tools: GoogleAIToolType[],\n    kwargs?: Partial<GoogleAIBaseLanguageModelCallOptions>\n  ): Runnable<\n    BaseLanguageModelInput,\n    AIMessageChunk,\n    GoogleAIBaseLanguageModelCallOptions\n  > {\n    return this.withConfig({ tools: convertToGeminiTools(tools), ...kwargs });\n  }\n\n  // Replace\n  _llmType() {\n    return \"chat_integration\";\n  }\n\n  /**\n   * Get the parameters used to invoke the model\n   */\n  override invocationParams(options?: this[\"ParsedCallOptions\"]) {\n    return copyAIModelParams(this, options);\n  }\n\n  async _generate(\n    messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    runManager: CallbackManagerForLLMRun | undefined\n  ): Promise<ChatResult> {\n    const parameters = this.invocationParams(options);\n    if (this.streaming) {\n      const stream = this._streamResponseChunks(messages, options, runManager);\n      let finalChunk: ChatGenerationChunk | null = null;\n      for await (const chunk of stream) {\n        finalChunk = !finalChunk ? chunk : concat(finalChunk, chunk);\n      }\n      if (!finalChunk) {\n        throw new Error(\"No chunks were returned from the stream.\");\n      }\n      return {\n        generations: [finalChunk],\n      };\n    }\n\n    const response = await this.connection.request(\n      messages,\n      parameters,\n      options,\n      runManager\n    );\n    const ret = this.connection.api.responseToChatResult(response);\n    const chunk = ret?.generations?.[0];\n    if (chunk) {\n      await runManager?.handleLLMNewToken(chunk.text || \"\");\n    }\n    return ret;\n  }\n\n  async *_streamResponseChunks(\n    _messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): AsyncGenerator<ChatGenerationChunk> {\n    // Make the call as a streaming request\n    const parameters = this.invocationParams(options);\n    const response = await this.streamedConnection.request(\n      _messages,\n      parameters,\n      options,\n      runManager\n    );\n\n    // Get the streaming parser of the response\n    const stream = response.data as JsonStream;\n    let usageMetadata: UsageMetadata | undefined;\n    // Loop until the end of the stream\n    // During the loop, yield each time we get a chunk from the streaming parser\n    // that is either available or added to the queue\n    while (!stream.streamDone) {\n      const output = await stream.nextChunk();\n      await runManager?.handleCustomEvent(\n        `google-chunk-${this.constructor.name}`,\n        {\n          output,\n        }\n      );\n      if (\n        output &&\n        output.usageMetadata &&\n        this.streamUsage !== false &&\n        options.streamUsage !== false\n      ) {\n        usageMetadata = {\n          input_tokens: output.usageMetadata.promptTokenCount,\n          output_tokens: output.usageMetadata.candidatesTokenCount,\n          total_tokens: output.usageMetadata.totalTokenCount,\n        };\n      }\n      const chunk =\n        output !== null\n          ? this.connection.api.responseToChatGeneration({ data: output })\n          : new ChatGenerationChunk({\n              text: \"\",\n              generationInfo: { finishReason: \"stop\" },\n              message: new AIMessageChunk({\n                content: \"\",\n                usage_metadata: usageMetadata,\n              }),\n            });\n      if (chunk) {\n        yield chunk;\n        await runManager?.handleLLMNewToken(\n          chunk.text ?? \"\",\n          undefined,\n          undefined,\n          undefined,\n          undefined,\n          { chunk }\n        );\n      }\n    }\n  }\n\n  /** @ignore */\n  _combineLLMOutput() {\n    return [];\n  }\n\n  /**\n   * Return profiling information for the model.\n   *\n   * Provides information about the model's capabilities and constraints,\n   * including token limits, multimodal support, and advanced features like\n   * tool calling and structured output.\n   *\n   * @returns {ModelProfile} An object describing the model's capabilities and constraints\n   */\n  get profile(): ModelProfile {\n    return PROFILES[this.model] ?? {};\n  }\n\n  withStructuredOutput<\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    RunOutput extends Record<string, any> = Record<string, any>\n  >(\n    outputSchema:\n      | InteropZodType<RunOutput>\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      | Record<string, any>,\n    config?: StructuredOutputMethodOptions<false>\n  ): Runnable<BaseLanguageModelInput, RunOutput>;\n\n  withStructuredOutput<\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    RunOutput extends Record<string, any> = Record<string, any>\n  >(\n    outputSchema:\n      | InteropZodType<RunOutput>\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      | Record<string, any>,\n    config?: StructuredOutputMethodOptions<true>\n  ): Runnable<BaseLanguageModelInput, { raw: BaseMessage; parsed: RunOutput }>;\n\n  withStructuredOutput<\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    RunOutput extends Record<string, any> = Record<string, any>\n  >(\n    outputSchema:\n      | InteropZodType<RunOutput>\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      | Record<string, any>,\n    config?: StructuredOutputMethodOptions<boolean>\n  ):\n    | Runnable<BaseLanguageModelInput, RunOutput>\n    | Runnable<\n        BaseLanguageModelInput,\n        { raw: BaseMessage; parsed: RunOutput }\n      > {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const schema: InteropZodType<RunOutput> | Record<string, any> =\n      outputSchema;\n    const name = config?.name;\n    const method = config?.method;\n    const includeRaw = config?.includeRaw;\n    if (method === \"jsonMode\") {\n      throw new Error(`Google only supports \"functionCalling\" as a method.`);\n    }\n\n    let functionName = name ?? \"extract\";\n    let outputParser: BaseLLMOutputParser<RunOutput>;\n    let tools: GeminiTool[];\n    if (isInteropZodSchema(schema)) {\n      const jsonSchema = schemaToGeminiParameters(schema);\n      tools = [\n        {\n          functionDeclarations: [\n            {\n              name: functionName,\n              description:\n                jsonSchema.description ?? \"A function available to call.\",\n              parameters: jsonSchema as GeminiFunctionSchema,\n            },\n          ],\n        },\n      ];\n      outputParser = new JsonOutputKeyToolsParser({\n        returnSingle: true,\n        keyName: functionName,\n        zodSchema: schema,\n      });\n    } else {\n      let geminiFunctionDefinition: GeminiFunctionDeclaration;\n      if (\n        typeof schema.name === \"string\" &&\n        typeof schema.parameters === \"object\" &&\n        schema.parameters != null\n      ) {\n        geminiFunctionDefinition = schema as GeminiFunctionDeclaration;\n        functionName = schema.name;\n      } else {\n        // We are providing the schema for *just* the parameters, probably\n        const parameters: GeminiJsonSchema = removeAdditionalProperties(schema);\n        geminiFunctionDefinition = {\n          name: functionName,\n          description: schema.description ?? \"\",\n          parameters,\n        };\n      }\n      tools = [\n        {\n          functionDeclarations: [geminiFunctionDefinition],\n        },\n      ];\n      outputParser = new JsonOutputKeyToolsParser<RunOutput>({\n        returnSingle: true,\n        keyName: functionName,\n      });\n    }\n    const llm = this.bindTools(tools).withConfig({ tool_choice: functionName });\n\n    if (!includeRaw) {\n      return llm.pipe(outputParser).withConfig({\n        runName: \"ChatGoogleStructuredOutput\",\n      }) as Runnable<BaseLanguageModelInput, RunOutput>;\n    }\n\n    const parserAssign = RunnablePassthrough.assign({\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      parsed: (input: any, config) => outputParser.invoke(input.raw, config),\n    });\n    const parserNone = RunnablePassthrough.assign({\n      parsed: () => null,\n    });\n    const parsedWithFallback = parserAssign.withFallbacks({\n      fallbacks: [parserNone],\n    });\n    return RunnableSequence.from<\n      BaseLanguageModelInput,\n      { raw: BaseMessage; parsed: RunOutput }\n    >([\n      {\n        raw: llm,\n      },\n      parsedWithFallback,\n    ]).withConfig({\n      runName: \"StructuredOutputRunnable\",\n    });\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;AAqEA,IAAa,iBAAb,cAAiDA,+CAG/C;CACA;CAEA,YACEC,QACAC,QACAC,QACAC,WACA;EACA,MAAM,QAAQ,QAAQ,QAAQ,UAAU;EACxC,KAAK,qCACH,QAAQ;CACX;CAED,IAAI,uBAAgC;AAClC,SAAO,OAAO,KAAK,uCAAuC,YACtD,CAAC,KAAK,qCACN,KAAK;CACV;CAED,IAAI,8BAAuC;AAIzC,MAAI,KAAK,gBAAgB,OACvB,QAAO;WACE,KAAK,cAAc,qBAC5B,QAAO;WACE,KAAK,UAAU,WAAW,oBAAoB,CACvD,QAAO;WACE,KAAK,UAAU,WAAW,wBAAwB,CAC3D,QAAO;WACE,KAAK,cAAc,gBAAgB,KAAK,aAAa,MAE9D,QAAO;WACE,KAAK,gBAAgB,QAG9B,QAAO;AAET,SAAO;CACR;CAED,6CAGE;AACA,MAAI,KAAK,UAAU,WAAW,aAAa,CACzC,QAAO;WACE,KAAK,UAAU,WAAW,aAAa,CAChD,QAAO;MAEP,QAAO;CAEV;CAED,kCACEC,WACwC;EACxC,MAAM,MAAM,UAAU;AACtB,MAAI,QAAQ,UAAa,QAAQ,KAC/B,QAAO,KAAK,4CAA4C;MAExD,QAAO;CAEV;CAED,iBAA8B;EAC5B,MAAMA,YACH,KAAK,aAAiC,CAAE;EAC3C,MAAM,6BACJ,KAAK,kCAAkC,UAAU;EACnD,MAAMC,eAAgC;GACpC,sBAAsB,KAAK;GAC3B;GACA,GAAG;EACJ;AACD,SAAOC,4BAAa,aAAa;CAClC;CAED,IAAI,MAAmB;AACrB,UAAQ,KAAK,SAAb;GACE,KAAK,SACH,QAAO,KAAK,gBAAgB;GAC9B,QACE,QAAO,MAAM;EAChB;CACF;AACF;;;;AAgBD,IAAsB,iBAAtB,cACUC,2DAEV;CAEE,OAAO,UAAU;AACf,SAAO;CACR;CAED,IAAI,aAAoD;AACtD,SAAO,EACL,aAAa,sBACd;CACF;CAED,kBAAkB;CAGlB;CAEA,YAAY;CAEZ;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,gBAA0B,CAAE;CAE5B;CAEA,cAAsB;CAEtB,iBAA0C,CAAE;CAE5C;CAGA;CAEA;CAEA;CAEA,cAAc;CAEd,YAAY;CAEZ;CAEA,AAAU;CAEV,AAAU;CAEV,YAAYC,QAA2C;EACrD,MAAMC,oCAAa,OAAO,CAAC;EAE3BC,8CAA+B,QAAQ,KAAK;EAC5C,KAAK,gBACH,QAAQ,iBAAiB,IAAIC;EAC/B,KAAK,cAAc,QAAQ,eAAe,KAAK;EAC/C,MAAM,SAAS,KAAK,YAAY,OAAO;EACvC,KAAK,gBAAgB,UAAU,CAAE,GAAE,OAAO;CAC3C;CAED,YAAYC,SAAqD;EAC/D,MAAM,SAAS,KAAK,iBAAiB,QAAQ;AAC7C,SAAO;GACL,aAAa;GACb,eAAe,KAAK;GACpB,eAAe;GACf,gBAAgB,OAAO,eAAe;GACtC,eAAe,OAAO,mBAAmB;GACzC,SAAS,QAAQ;EAClB;CACF;CAMD,kBAAkBC,QAAwC;AACxD,SAAO,IAAIC,8BAAiB;CAC7B;CAED,YAAYC,QAAgE;AAC1E,SAAO,QAAQ,iEAAiC,iBAAiB;CAClE;CAED,YACEA,QACwB;EACxB,MAAM,SAAS,KAAK,YAAY,OAAO;AACvC,MAAI,OACF,QAAO,KAAK,kBAAkB,OAAO;MAErC,QAAO,KAAK,sBAAsB,OAAO;CAE5C;CAED,gBACEC,QACAd,QACA;EACA,KAAK,aAAa,IAAI,eACpB;GAAE,GAAG;GAAQ,GAAG;EAAM,GACtB,KAAK,QACL,QACA;EAGF,KAAK,qBAAqB,IAAI,eAC5B;GAAE,GAAG;GAAQ,GAAG;EAAM,GACtB,KAAK,QACL,QACA;CAEH;CAED,IAAI,WAA+B;AACjC,SAAO,KAAK,WAAW;CACxB;CAED,AAAS,UACPe,OACAC,QAKA;AACA,SAAO,KAAK,WAAW;GAAE,OAAOC,oCAAqB,MAAM;GAAE,GAAG;EAAQ,EAAC;CAC1E;CAGD,WAAW;AACT,SAAO;CACR;;;;CAKD,AAAS,iBAAiBC,SAAqC;AAC7D,SAAOC,iCAAkB,MAAM,QAAQ;CACxC;CAED,MAAM,UACJC,UACAV,SACAW,YACqB;EACrB,MAAM,aAAa,KAAK,iBAAiB,QAAQ;AACjD,MAAI,KAAK,WAAW;GAClB,MAAM,SAAS,KAAK,sBAAsB,UAAU,SAAS,WAAW;GACxE,IAAIC,aAAyC;AAC7C,cAAW,MAAMC,WAAS,QACxB,aAAa,CAAC,aAAaA,oDAAe,YAAYA,QAAM;AAE9D,OAAI,CAAC,WACH,OAAM,IAAI,MAAM;AAElB,UAAO,EACL,aAAa,CAAC,UAAW,EAC1B;EACF;EAED,MAAM,WAAW,MAAM,KAAK,WAAW,QACrC,UACA,YACA,SACA,WACD;EACD,MAAM,MAAM,KAAK,WAAW,IAAI,qBAAqB,SAAS;EAC9D,MAAM,QAAQ,KAAK,cAAc;AACjC,MAAI,OACF,MAAM,YAAY,kBAAkB,MAAM,QAAQ,GAAG;AAEvD,SAAO;CACR;CAED,OAAO,sBACLC,WACAd,SACAe,YACqC;EAErC,MAAM,aAAa,KAAK,iBAAiB,QAAQ;EACjD,MAAM,WAAW,MAAM,KAAK,mBAAmB,QAC7C,WACA,YACA,SACA,WACD;EAGD,MAAM,SAAS,SAAS;EACxB,IAAIC;AAIJ,SAAO,CAAC,OAAO,YAAY;GACzB,MAAM,SAAS,MAAM,OAAO,WAAW;GACvC,MAAM,YAAY,kBAChB,CAAC,aAAa,EAAE,KAAK,YAAY,MAAM,EACvC,EACE,OACD,EACF;AACD,OACE,UACA,OAAO,iBACP,KAAK,gBAAgB,SACrB,QAAQ,gBAAgB,OAExB,gBAAgB;IACd,cAAc,OAAO,cAAc;IACnC,eAAe,OAAO,cAAc;IACpC,cAAc,OAAO,cAAc;GACpC;GAEH,MAAM,QACJ,WAAW,OACP,KAAK,WAAW,IAAI,yBAAyB,EAAE,MAAM,OAAQ,EAAC,GAC9D,IAAIC,6CAAoB;IACtB,MAAM;IACN,gBAAgB,EAAE,cAAc,OAAQ;IACxC,SAAS,IAAIC,yCAAe;KAC1B,SAAS;KACT,gBAAgB;IACjB;GACF;AACP,OAAI,OAAO;IACT,MAAM;IACN,MAAM,YAAY,kBAChB,MAAM,QAAQ,IACd,QACA,QACA,QACA,QACA,EAAE,MAAO,EACV;GACF;EACF;CACF;;CAGD,oBAAoB;AAClB,SAAO,CAAE;CACV;;;;;;;;;;CAWD,IAAI,UAAwB;AAC1B,SAAOC,yBAAS,KAAK,UAAU,CAAE;CAClC;CAwBD,qBAIEC,cAIAC,QAMI;EAEJ,MAAMC,SACJ;EACF,MAAM,OAAO,QAAQ;EACrB,MAAM,SAAS,QAAQ;EACvB,MAAM,aAAa,QAAQ;AAC3B,MAAI,WAAW,WACb,OAAM,IAAI,MAAM,CAAC,mDAAmD,CAAC;EAGvE,IAAI,eAAe,QAAQ;EAC3B,IAAIC;EACJ,IAAIC;AACJ,2DAAuB,OAAO,EAAE;GAC9B,MAAM,aAAaC,0DAAyB,OAAO;GACnD,QAAQ,CACN,EACE,sBAAsB,CACpB;IACE,MAAM;IACN,aACE,WAAW,eAAe;IAC5B,YAAY;GACb,CACF,EACF,CACF;GACD,eAAe,IAAIC,sEAAyB;IAC1C,cAAc;IACd,SAAS;IACT,WAAW;GACZ;EACF,OAAM;GACL,IAAIC;AACJ,OACE,OAAO,OAAO,SAAS,YACvB,OAAO,OAAO,eAAe,YAC7B,OAAO,cAAc,MACrB;IACA,2BAA2B;IAC3B,eAAe,OAAO;GACvB,OAAM;IAEL,MAAMC,aAA+BC,4DAA2B,OAAO;IACvE,2BAA2B;KACzB,MAAM;KACN,aAAa,OAAO,eAAe;KACnC;IACD;GACF;GACD,QAAQ,CACN,EACE,sBAAsB,CAAC,wBAAyB,EACjD,CACF;GACD,eAAe,IAAIH,sEAAoC;IACrD,cAAc;IACd,SAAS;GACV;EACF;EACD,MAAM,MAAM,KAAK,UAAU,MAAM,CAAC,WAAW,EAAE,aAAa,aAAc,EAAC;AAE3E,MAAI,CAAC,WACH,QAAO,IAAI,KAAK,aAAa,CAAC,WAAW,EACvC,SAAS,6BACV,EAAC;EAGJ,MAAM,eAAeI,+CAAoB,OAAO,EAE9C,QAAQ,CAACC,OAAYC,aAAW,aAAa,OAAO,MAAM,KAAKA,SAAO,CACvE,EAAC;EACF,MAAM,aAAaF,+CAAoB,OAAO,EAC5C,QAAQ,MAAM,KACf,EAAC;EACF,MAAM,qBAAqB,aAAa,cAAc,EACpD,WAAW,CAAC,UAAW,EACxB,EAAC;AACF,SAAOG,4CAAiB,KAGtB,CACA,EACE,KAAK,IACN,GACD,kBACD,EAAC,CAAC,WAAW,EACZ,SAAS,2BACV,EAAC;CACH;AACF"}