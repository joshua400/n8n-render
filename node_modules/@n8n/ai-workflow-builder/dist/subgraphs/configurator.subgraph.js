"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ConfiguratorSubgraph = exports.ConfiguratorSubgraphState = void 0;
const prompts_1 = require("@langchain/core/prompts");
const langgraph_1 = require("@langchain/langgraph");
const errors_1 = require("../errors");
const subgraph_interface_1 = require("./subgraph-interface");
const get_node_parameter_tool_1 = require("../tools/get-node-parameter.tool");
const update_node_parameters_tool_1 = require("../tools/update-node-parameters.tool");
const validate_configuration_tool_1 = require("../tools/validate-configuration.tool");
const coordination_1 = require("../types/coordination");
const langchain_1 = require("../types/langchain");
const cache_control_1 = require("../utils/cache-control");
const context_builders_1 = require("../utils/context-builders");
const operations_processor_1 = require("../utils/operations-processor");
const subgraph_helpers_1 = require("../utils/subgraph-helpers");
const CONFIGURATOR_PROMPT = `You are a Configurator Agent specialized in setting up n8n node parameters.

MANDATORY EXECUTION SEQUENCE:
You MUST follow these steps IN ORDER. Do not skip any step.

STEP 1: CONFIGURE ALL NODES
- Call update_node_parameters for EVERY node in the workflow
- Configure multiple nodes in PARALLEL for efficiency
- Do NOT respond with text - START CONFIGURING immediately

STEP 2: VALIDATE (REQUIRED)
- After ALL configurations complete, call validate_configuration
- This step is MANDATORY - you cannot finish without it
- If validation finds issues, fix them and validate again

STEP 3: RESPOND TO USER
- Only after validation passes, provide your response

NEVER respond to the user without calling validate_configuration first

WORKFLOW JSON DETECTION:
- You receive <current_workflow_json> in your context
- If you see nodes in the workflow JSON, you MUST configure them IMMEDIATELY
- Look at the workflow JSON, identify each node, and call update_node_parameters for ALL of them

PARAMETER CONFIGURATION:
Use update_node_parameters with natural language instructions:
- "Set URL to https://api.example.com/weather"
- "Add header Authorization: Bearer token"
- "Set method to POST"
- "Add field 'status' with value 'processed'"

SPECIAL EXPRESSIONS FOR TOOL NODES:
Tool nodes (types ending in "Tool") support $fromAI expressions:
- "Set sendTo to ={{ $fromAI('to') }}"
- "Set subject to ={{ $fromAI('subject') }}"
- "Set message to ={{ $fromAI('message_html') }}"
- "Set timeMin to ={{ $fromAI('After', '', 'string') }}"

$fromAI syntax: ={{ $fromAI('key', 'description', 'type', defaultValue) }}
- ONLY use in tool nodes (check node type ends with "Tool")
- Use for dynamic values that AI determines at runtime
- For regular nodes, use static values or standard expressions

CRITICAL PARAMETERS TO ALWAYS SET:
- HTTP Request: URL, method, headers (if auth needed)
- Set node: Fields to set with values
- Code node: The actual code to execute
- IF node: Conditions to check
- Document Loader: dataType parameter ('binary' for files like PDF, 'json' for JSON data)
- AI nodes: Prompts, models, configurations
- Tool nodes: Use $fromAI for dynamic recipient/subject/message fields

NEVER RELY ON DEFAULT VALUES:
Defaults are traps that cause runtime failures. Examples:
- Document Loader defaults to 'json' but MUST be 'binary' when processing files
- HTTP Request defaults to GET but APIs often need POST
- Vector Store mode affects available connections - set explicitly (retrieve-as-tool when using with AI Agent)

<response_format>
After validation passes, provide a concise summary:
- List any placeholders requiring user configuration (e.g., "URL placeholder needs actual endpoint")
- Note which nodes were configured and key settings applied
- Keep it brief - this output is used for coordination with other LLM agents, not displayed directly to users
</response_format>

DO NOT:
- Respond before calling validate_configuration
- Skip validation even if you think configuration is correct
- Add commentary between tool calls - execute tools silently`;
const INSTANCE_URL_PROMPT = `
<instance_url>
The n8n instance base URL is: {instanceUrl}

This URL is essential for webhook nodes and chat triggers as it provides the base URL for:
- Webhook URLs that external services need to call
- Chat trigger URLs for conversational interfaces
- Any node that requires the full instance URL to generate proper callback URLs

When working with webhook or chat trigger nodes, use this URL as the base for constructing proper endpoint URLs.
</instance_url>
`;
exports.ConfiguratorSubgraphState = langgraph_1.Annotation.Root({
    workflowJSON: (0, langgraph_1.Annotation)({
        reducer: (x, y) => y ?? x,
        default: () => ({ nodes: [], connections: {}, name: '' }),
    }),
    workflowContext: (0, langgraph_1.Annotation)({
        reducer: (x, y) => y ?? x,
    }),
    instanceUrl: (0, langgraph_1.Annotation)({
        reducer: (x, y) => y ?? x,
        default: () => '',
    }),
    userRequest: (0, langgraph_1.Annotation)({
        reducer: (x, y) => y ?? x,
        default: () => '',
    }),
    discoveryContext: (0, langgraph_1.Annotation)({
        reducer: (x, y) => y ?? x,
        default: () => null,
    }),
    messages: (0, langgraph_1.Annotation)({
        reducer: (x, y) => x.concat(y),
        default: () => [],
    }),
    workflowOperations: (0, langgraph_1.Annotation)({
        reducer: (x, y) => {
            if (y === null)
                return [];
            if (!y || y.length === 0)
                return x ?? [];
            return [...(x ?? []), ...y];
        },
        default: () => [],
    }),
});
class ConfiguratorSubgraph extends subgraph_interface_1.BaseSubgraph {
    name = 'configurator_subgraph';
    description = 'Configures node parameters after structure is built';
    agent;
    toolMap;
    instanceUrl = '';
    create(config) {
        this.instanceUrl = config.instanceUrl ?? '';
        const tools = [
            (0, update_node_parameters_tool_1.createUpdateNodeParametersTool)(config.parsedNodeTypes, config.llm, config.logger, config.instanceUrl),
            (0, get_node_parameter_tool_1.createGetNodeParameterTool)(),
            (0, validate_configuration_tool_1.createValidateConfigurationTool)(config.parsedNodeTypes),
        ];
        this.toolMap = new Map(tools.map((bt) => [bt.tool.name, bt.tool]));
        const systemPromptTemplate = prompts_1.ChatPromptTemplate.fromMessages([
            [
                'system',
                [
                    {
                        type: 'text',
                        text: CONFIGURATOR_PROMPT,
                    },
                    {
                        type: 'text',
                        text: INSTANCE_URL_PROMPT,
                        cache_control: { type: 'ephemeral' },
                    },
                ],
            ],
            ['placeholder', '{messages}'],
        ]);
        if (typeof config.llm.bindTools !== 'function') {
            throw new errors_1.LLMServiceError('LLM does not support tools', {
                llmModel: config.llm._llmType(),
            });
        }
        this.agent = systemPromptTemplate.pipe(config.llm.bindTools(tools.map((bt) => bt.tool)));
        const callAgent = async (state) => {
            (0, cache_control_1.applySubgraphCacheMarkers)(state.messages);
            const response = await this.agent.invoke({
                messages: state.messages,
                instanceUrl: state.instanceUrl ?? '',
            });
            if (!(0, langchain_1.isBaseMessage)(response)) {
                throw new errors_1.LLMServiceError('Configurator agent did not return a valid message');
            }
            return { messages: [response] };
        };
        const subgraph = new langgraph_1.StateGraph(exports.ConfiguratorSubgraphState)
            .addNode('agent', callAgent)
            .addNode('tools', async (state) => await (0, subgraph_helpers_1.executeSubgraphTools)(state, this.toolMap))
            .addNode('process_operations', operations_processor_1.processOperations)
            .addEdge('__start__', 'agent')
            .addConditionalEdges('agent', (0, subgraph_helpers_1.createStandardShouldContinue)())
            .addEdge('tools', 'process_operations')
            .addEdge('process_operations', 'agent');
        return subgraph.compile();
    }
    transformInput(parentState) {
        const userRequest = (0, subgraph_helpers_1.extractUserRequest)(parentState.messages);
        const contextParts = [];
        if (userRequest) {
            contextParts.push('=== USER REQUEST ===');
            contextParts.push(userRequest);
        }
        if (parentState.discoveryContext?.bestPractices) {
            contextParts.push(parentState.discoveryContext.bestPractices);
        }
        contextParts.push('=== WORKFLOW TO CONFIGURE ===');
        contextParts.push((0, context_builders_1.buildWorkflowJsonBlock)(parentState.workflowJSON));
        contextParts.push('=== EXECUTION CONTEXT ===');
        contextParts.push((0, context_builders_1.buildExecutionContextBlock)(parentState.workflowContext));
        const contextMessage = (0, context_builders_1.createContextMessage)(contextParts);
        return {
            workflowJSON: parentState.workflowJSON,
            workflowContext: parentState.workflowContext,
            instanceUrl: this.instanceUrl,
            userRequest,
            discoveryContext: parentState.discoveryContext,
            messages: [contextMessage],
        };
    }
    transformOutput(subgraphOutput, _parentState) {
        const lastMessage = subgraphOutput.messages[subgraphOutput.messages.length - 1];
        const setupInstructions = typeof lastMessage?.content === 'string' ? lastMessage.content : 'Configuration complete';
        const nodesConfigured = subgraphOutput.workflowJSON.nodes.length;
        const hasSetupInstructions = setupInstructions.includes('Setup') ||
            setupInstructions.includes('setup') ||
            setupInstructions.length > 50;
        const logEntry = {
            phase: 'configurator',
            status: 'completed',
            timestamp: Date.now(),
            summary: `Configured ${nodesConfigured} nodes`,
            output: setupInstructions,
            metadata: (0, coordination_1.createConfiguratorMetadata)({
                nodesConfigured,
                hasSetupInstructions,
            }),
        };
        return {
            workflowJSON: subgraphOutput.workflowJSON,
            workflowOperations: subgraphOutput.workflowOperations ?? [],
            coordinationLog: [logEntry],
        };
    }
}
exports.ConfiguratorSubgraph = ConfiguratorSubgraph;
//# sourceMappingURL=configurator.subgraph.js.map